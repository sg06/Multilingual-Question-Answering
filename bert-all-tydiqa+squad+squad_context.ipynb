{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:38:11.776940Z","iopub.status.busy":"2022-04-10T12:38:11.774416Z","iopub.status.idle":"2022-04-10T12:38:35.489717Z","shell.execute_reply":"2022-04-10T12:38:35.488851Z","shell.execute_reply.started":"2022-04-10T12:38:11.776897Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.16.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.11.6)\n","Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.49)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.18.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.4.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.62.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.20.3)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.26.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.2.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.3)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.6)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.4.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.26.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (21.3)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.11.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.1.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.62.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface_hub) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.7)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["! pip install transformers \n","! pip install datasets \n","! pip install huggingface_hub"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:38:58.789098Z","iopub.status.busy":"2022-04-10T12:38:58.788312Z","iopub.status.idle":"2022-04-10T12:38:58.873346Z","shell.execute_reply":"2022-04-10T12:38:58.872690Z","shell.execute_reply.started":"2022-04-10T12:38:58.789060Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c04416e8b174c6ab24528be78b4e3cb","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["#from huggingface_hub import notebook_login\n","\n","#notebook_login()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.405388Z","iopub.status.busy":"2022-04-10T12:39:06.405084Z","iopub.status.idle":"2022-04-10T12:39:06.409459Z","shell.execute_reply":"2022-04-10T12:39:06.408724Z","shell.execute_reply.started":"2022-04-10T12:39:06.405345Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.420026Z","iopub.status.busy":"2022-04-10T12:39:06.419684Z","iopub.status.idle":"2022-04-10T12:39:06.477740Z","shell.execute_reply":"2022-04-10T12:39:06.476986Z","shell.execute_reply.started":"2022-04-10T12:39:06.419996Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.16.2\n"]}],"source":["import transformers\n","print(transformers.__version__)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.479711Z","iopub.status.busy":"2022-04-10T12:39:06.479443Z","iopub.status.idle":"2022-04-10T12:39:06.483753Z","shell.execute_reply":"2022-04-10T12:39:06.482845Z","shell.execute_reply.started":"2022-04-10T12:39:06.479668Z"},"trusted":true},"outputs":[],"source":["model_checkpoint = \"bert-base-multilingual-cased\"\n","batch_size = 16"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.485841Z","iopub.status.busy":"2022-04-10T12:39:06.484904Z","iopub.status.idle":"2022-04-10T12:39:12.854891Z","shell.execute_reply":"2022-04-10T12:39:12.854026Z","shell.execute_reply.started":"2022-04-10T12:39:06.485764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  git-lfs\n","0 upgraded, 1 newly installed, 0 to remove and 75 not upgraded.\n","Need to get 3316 kB of archives.\n","After this operation, 11.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\n","Fetched 3316 kB in 2s (2114 kB/s)  \u001b[0m33m\u001b[33m\u001b[33m\n","\n","\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\n","(Reading database ... 103274 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\n","\n","\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"]}],"source":["# !apt install git-lfs\n","# !git config --global user.email \"patelkrinal214@gmail.com\"\n","# !git config --global user.name \"krinal214\""]},{"cell_type":"markdown","metadata":{},"source":["### Loading the dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:12.857515Z","iopub.status.busy":"2022-04-10T12:39:12.857293Z","iopub.status.idle":"2022-04-10T12:39:13.290649Z","shell.execute_reply":"2022-04-10T12:39:13.289831Z","shell.execute_reply.started":"2022-04-10T12:39:12.857490Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset, load_metric"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:13.294576Z","iopub.status.busy":"2022-04-10T12:39:13.294357Z","iopub.status.idle":"2022-04-10T12:41:16.403445Z","shell.execute_reply":"2022-04-10T12:41:16.402677Z","shell.execute_reply.started":"2022-04-10T12:39:13.294538Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6691890a9194cc691d958578744531b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/3.49k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36481865ffdb43bc93fe9bc22a522bb9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset tydiqa/secondary_task (download: 1.82 GiB, generated: 55.27 MiB, post-processed: Unknown size, total: 1.87 GiB) to /root/.cache/huggingface/datasets/tydiqa/secondary_task/1.0.0/b8a6c4c0db10bf5703d7b36645e5dbae821b8c0e902dac9daeecd459a8337148...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42cc400a865a43c89646ab085cf33a02","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92e0cf1f69784f2c8cd7f7fc0b173739","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"622ce2bd652c4fe4ad88c37cdcb7e85f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/161M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"620264eb2ede41a797ba9f85d448e30a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"035728ae73e345c5bdff3b6269f3451a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1adfa65280d54691880a1dd4f8e3859c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/58.0M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"594b20065c834a26b00924694772798d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/5.62M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b2bc904c2a14a329308c3d2c94fc399","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset tydiqa downloaded and prepared to /root/.cache/huggingface/datasets/tydiqa/secondary_task/1.0.0/b8a6c4c0db10bf5703d7b36645e5dbae821b8c0e902dac9daeecd459a8337148. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1c867f6fdfb4c85b09b9ce590b83ea6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 49881\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 5077\n","    })\n","})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["datasets=load_dataset(\"tydiqa\",\"secondary_task\")\n","datasets"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:16.405624Z","iopub.status.busy":"2022-04-10T12:41:16.404752Z","iopub.status.idle":"2022-04-10T12:41:24.098638Z","shell.execute_reply":"2022-04-10T12:41:24.097861Z","shell.execute_reply.started":"2022-04-10T12:41:16.405587Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec6f106bc69940a6ad50ea67fc24d1ea","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/default (download: 20.08 MiB, generated: 50.65 MiB, post-processed: Unknown size, total: 70.73 MiB) to /root/.cache/huggingface/datasets/parquet/krinal214--squad_ben_tel_context-44f016df634c4eda/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ad109c7f3e845db843bea024f449c34","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"499c36451b8c44fdb62a69df28223358","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.70M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d77721585674fe4b94c4961c96eef7e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/15.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5b3ce2420da4bc5b5df4aae01a38666","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/3.61M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52a9a5aec99048e6bd2f2a52b308d8b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/krinal214--squad_ben_tel_context-44f016df634c4eda/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eec8a574f8c64e63a8fb569c2fb13deb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset1=load_dataset('krinal214/squad_ben_tel_context')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:24.100819Z","iopub.status.busy":"2022-04-10T12:41:24.100251Z","iopub.status.idle":"2022-04-10T12:41:24.107231Z","shell.execute_reply":"2022-04-10T12:41:24.106223Z","shell.execute_reply.started":"2022-04-10T12:41:24.100761Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    test: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 7880\n","    })\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 57070\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 14301\n","    })\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["dataset1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:24.109611Z","iopub.status.busy":"2022-04-10T12:41:24.109015Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73ac75c1377342cca1a6af04298e5730","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aacc56cb37a248ca90ea6bbd2ab5df0d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7373697d3af423394aab7c5a914085c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3dadd273b4ae47268916d36a2ed67230","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a079f22fc2f4592bc3b8b8b2fc7f25e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb35bf3b9f6c4dd1ac6574175d1c4ad9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"999eef48bf2d4e1e935eaeff4e58ccdc","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset2=load_dataset('squad')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import concatenate_datasets\n","datasets['train']=concatenate_datasets([datasets['train'],dataset1['train']])\n","datasets['train']=concatenate_datasets([datasets['train'],dataset2['train']])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import re\n","def filter_dataset(ds,lang):\n","    def check(d):\n","        for i in lang:\n","            if re.search(i,d):\n","                return True\n","        return False\n","    ds = ds.filter(lambda x: check(x['id']))\n","    return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import ClassLabel, Sequence\n","import random\n","import pandas as pd\n","from IPython.display import display, HTML\n","\n","\n","def show_random_elements(dataset, num_examples=8):\n","    picks = random.sample(range(0, len(dataset)-1), num_examples)\n","    df = pd.DataFrame(dataset[picks])\n","    display(HTML(df.to_html()))"]},{"cell_type":"markdown","metadata":{},"source":["### Preparing the training and validation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# datasets[\"train\"]=filter_dataset(datasets[\"validation\"],['bengali'])\n","datasets[\"validation\"]=filter_dataset(datasets[\"validation\"],['bengali', 'telugu'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["show_random_elements(datasets[\"train\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["max_length = 384  # The maximum length of a feature (question and context)\n","doc_stride = 160  # The allowed overlap between two part of the context when splitting is performed."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.status.idle":"2022-04-10T12:41:48.702350Z","shell.execute_reply":"2022-04-10T12:41:48.701697Z","shell.execute_reply.started":"2022-04-10T12:41:42.997337Z"},"trusted":true},"outputs":[],"source":["datasets['train']=datasets['train'].filter(lambda example: len(example['question'])<=max_length)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:48.703917Z","iopub.status.busy":"2022-04-10T12:41:48.703635Z","iopub.status.idle":"2022-04-10T12:41:48.708431Z","shell.execute_reply":"2022-04-10T12:41:48.707750Z","shell.execute_reply.started":"2022-04-10T12:41:48.703881Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 194549\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 782\n","    })\n","})\n"]}],"source":["print(datasets)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:48.711548Z","iopub.status.busy":"2022-04-10T12:41:48.711139Z","iopub.status.idle":"2022-04-10T12:41:48.734854Z","shell.execute_reply":"2022-04-10T12:41:48.733925Z","shell.execute_reply.started":"2022-04-10T12:41:48.711513Z"},"trusted":true},"outputs":[],"source":["def prepare_train_features(examples):\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","    tokenized_examples = tokenizer(\n","        examples[\"question\"],\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n","\n","    # Let's label those examples!\n","    tokenized_examples[\"start_positions\"] = []\n","    tokenized_examples[\"end_positions\"] = []\n","\n","    for i, offsets in enumerate(offset_mapping):\n","        # We will label impossible answers with the index of the CLS token.\n","        input_ids = tokenized_examples[\"input_ids\"][i]\n","        cls_index = input_ids.index(tokenizer.cls_token_id)\n","\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        answers = examples[\"answers\"][sample_index]\n","        # If no answers are given, set the cls_index as answer.\n","        if len(answers[\"answer_start\"]) == 0:\n","            tokenized_examples[\"start_positions\"].append(cls_index)\n","            tokenized_examples[\"end_positions\"].append(cls_index)\n","        else:\n","            # Start/end character index of the answer in the text.\n","            start_char = answers[\"answer_start\"][0]\n","            end_char = start_char + len(answers[\"text\"][0])\n","\n","            # Start token index of the current span in the text.\n","            token_start_index = 0\n","            while sequence_ids[token_start_index] != 1 :\n","                token_start_index += 1\n","\n","            # End token index of the current span in the text.\n","            token_end_index = len(input_ids) - 1\n","            while sequence_ids[token_end_index] != 1:\n","                token_end_index -= 1\n","    \n","            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n","            if not (\n","                offsets[token_start_index][0] <= start_char\n","                and offsets[token_end_index][1] >= end_char\n","            ):\n","                tokenized_examples[\"start_positions\"].append(cls_index)\n","                tokenized_examples[\"end_positions\"].append(cls_index)\n","            else:\n","                while (\n","                    token_start_index < len(offsets)\n","                    and offsets[token_start_index][0] <= start_char\n","                ):\n","                    token_start_index += 1\n","                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n","\n","    return tokenized_examples"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:48.736657Z","iopub.status.busy":"2022-04-10T12:41:48.736158Z","iopub.status.idle":"2022-04-10T12:44:18.890727Z","shell.execute_reply":"2022-04-10T12:44:18.890035Z","shell.execute_reply.started":"2022-04-10T12:41:48.736621Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"786386453bab456fa668d38b7aa59193","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/195 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0adef2c76d742db91464f61fef4e3d7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = datasets.map(\n","    prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:18.892339Z","iopub.status.busy":"2022-04-10T12:44:18.892002Z","iopub.status.idle":"2022-04-10T12:44:37.578336Z","shell.execute_reply":"2022-04-10T12:44:37.577682Z","shell.execute_reply.started":"2022-04-10T12:44:18.892301Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db131ac72c8a46d5b06ddf4714bb0701","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForQuestionAnswering\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:37.579899Z","iopub.status.busy":"2022-04-10T12:44:37.579553Z","iopub.status.idle":"2022-04-10T12:44:43.451871Z","shell.execute_reply":"2022-04-10T12:44:43.451084Z","shell.execute_reply.started":"2022-04-10T12:44:37.579860Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","/opt/conda/lib/python3.7/site-packages/transformers/training_args.py:951: FutureWarning: `--push_to_hub_model_id` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_model_id` instead and pass the full repo name to this argument (in this case krinal214/bert-all-squad_ben_tel_context).\n","  FutureWarning,\n"]}],"source":["from transformers import TrainingArguments, Trainer\n","model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    f\"{model_name}-finetuned-model\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=1,\n","    weight_decay=0.01,\n","    #push_to_hub = True,\n","    #push_to_hub_model_id = \"bert-all-squad_ben_tel_context\",\n","    save_steps=50000\n",")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:43.453736Z","iopub.status.busy":"2022-04-10T12:44:43.453306Z","iopub.status.idle":"2022-04-10T12:44:43.457735Z","shell.execute_reply":"2022-04-10T12:44:43.457057Z","shell.execute_reply.started":"2022-04-10T12:44:43.453687Z"},"trusted":true},"outputs":[],"source":["from transformers import DefaultDataCollator\n","\n","data_collator = DefaultDataCollator()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:43.459377Z","iopub.status.busy":"2022-04-10T12:44:43.458901Z","iopub.status.idle":"2022-04-10T12:44:56.009560Z","shell.execute_reply":"2022-04-10T12:44:56.008681Z","shell.execute_reply.started":"2022-04-10T12:44:43.459341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["Cloning https://huggingface.co/krinal214/bert-all-squad_ben_tel_context into local empty directory.\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:56.011713Z","iopub.status.busy":"2022-04-10T12:44:56.011435Z","iopub.status.idle":"2022-04-10T12:44:56.016711Z","shell.execute_reply":"2022-04-10T12:44:56.016006Z","shell.execute_reply.started":"2022-04-10T12:44:56.011667Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","        num_rows: 202801\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","        num_rows: 930\n","    })\n","})\n"]}],"source":["print(tokenized_datasets)"]},{"cell_type":"markdown","metadata":{},"source":["### Training the model"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:56.018619Z","iopub.status.busy":"2022-04-10T12:44:56.018149Z","iopub.status.idle":"2022-04-10T15:03:41.957136Z","shell.execute_reply":"2022-04-10T15:03:41.956441Z","shell.execute_reply.started":"2022-04-10T12:44:56.018582Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 202801\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12676\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12676' max='12676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12676/12676 2:18:44, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.996000</td>\n","      <td>0.539258</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 930\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=12676, training_loss=1.1739939421499967, metrics={'train_runtime': 8325.8954, 'train_samples_per_second': 24.358, 'train_steps_per_second': 1.522, 'total_flos': 3.974343267211315e+16, 'train_loss': 1.1739939421499967, 'epoch': 1.0})"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:41.958870Z","iopub.status.busy":"2022-04-10T15:03:41.958516Z","iopub.status.idle":"2022-04-10T15:03:41.969235Z","shell.execute_reply":"2022-04-10T15:03:41.968505Z","shell.execute_reply.started":"2022-04-10T15:03:41.958833Z"},"trusted":true},"outputs":[],"source":["def prepare_validation_features(examples):\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","\n","    \n","    tokenized_examples = tokenizer(\n","        examples[\"question\"],\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    \n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","\n","    # We keep the example_id that gave us this feature and we will store the offset mappings.\n","    tokenized_examples[\"example_id\"] = []\n","\n","    for i in range(len(tokenized_examples[\"input_ids\"])):\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","        context_index = 1 \n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n","\n","        tokenized_examples[\"offset_mapping\"][i] = [\n","            (o if sequence_ids[k] == context_index else None)\n","            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n","        ]\n","\n","    return tokenized_examples"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluating the model"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:41.974512Z","iopub.status.busy":"2022-04-10T15:03:41.973937Z","iopub.status.idle":"2022-04-10T15:03:41.986334Z","shell.execute_reply":"2022-04-10T15:03:41.985482Z","shell.execute_reply.started":"2022-04-10T15:03:41.974467Z"},"trusted":true},"outputs":[],"source":["max_answer_length = 50\n","n_best_answers=20"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:41.988845Z","iopub.status.busy":"2022-04-10T15:03:41.988483Z","iopub.status.idle":"2022-04-10T15:03:42.008073Z","shell.execute_reply":"2022-04-10T15:03:42.007010Z","shell.execute_reply.started":"2022-04-10T15:03:41.988805Z"},"trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","import numpy as np\n","\n","def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 50):\n","    all_start_logits, all_end_logits = raw_predictions\n","    # Build a map example to its corresponding features.\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","    features_per_example = collections.defaultdict(list)\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","    predictions = collections.OrderedDict()\n","    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n","\n","    # Let's loop over all the examples!\n","    for example_index, example in enumerate(tqdm(examples)):\n","        # Those are the indices of the features associated to the current example.\n","        feature_indices = features_per_example[example_index]\n","\n","        min_null_score = None # Only used if squad_v2 is True.\n","        valid_answers = []\n","        \n","        context = example[\"context\"]\n","        # Looping through all the features associated to the current example.\n","        for feature_index in feature_indices:\n","            # We grab the predictions of the model for this feature.\n","            start_logits = all_start_logits[feature_index]\n","            end_logits = all_end_logits[feature_index]\n","            # This is what will allow us to map some the positions in our logits to span of texts in the original\n","            # context.\n","            offset_mapping = features[feature_index][\"offset_mapping\"]\n","\n","            # Update minimum null prediction.\n","            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n","            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n","            if min_null_score is None or min_null_score < feature_null_score:\n","                min_null_score = feature_null_score\n","\n","            # Go through all possibilities for the `n_best_size` greater start and end logits.\n","            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n","                    # to part of the input_ids that are not in the context.\n","                    if (\n","                        start_index >= len(offset_mapping)\n","                        or end_index >= len(offset_mapping)\n","                        or offset_mapping[start_index] is None\n","                        or offset_mapping[end_index] is None\n","                        or len(offset_mapping[start_index])==0\n","                        or len(offset_mapping[end_index])==0\n","                    ):\n","                        continue\n","                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n","                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n","                        continue\n","\n","                    try:\n","                        start_char = offset_mapping[start_index][0]\n","                        end_char = offset_mapping[end_index][1]\n","                        valid_answers.append(\n","                            {\n","                                \"score\": start_logits[start_index] + end_logits[end_index],\n","                                \"text\": context[start_char: end_char]\n","                            }\n","                        )\n","                    except IndexError:\n","                        continue\n","\n","        \n","        if len(valid_answers) > 0:\n","            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n","        else:\n","            best_answer = {\"text\": \"\", \"score\": 0.0}\n","        \n","        predictions[example[\"id\"]] = best_answer[\"text\"]\n","        \n","    return predictions\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:42.010519Z","iopub.status.busy":"2022-04-10T15:03:42.009690Z","iopub.status.idle":"2022-04-10T15:03:42.024916Z","shell.execute_reply":"2022-04-10T15:03:42.024128Z","shell.execute_reply.started":"2022-04-10T15:03:42.010477Z"},"trusted":true},"outputs":[],"source":["import collections\n","def evaluate(ds,wrong_pred,language):\n","    val_dataset=filter_dataset(ds,language)\n","    validation_features = val_dataset.map(\n","        prepare_validation_features,\n","        batched=True,\n","        remove_columns=val_dataset.column_names\n","    )\n","    raw_predictions = trainer.predict(validation_features)\n","    validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n","    \n","    examples = val_dataset\n","    features = validation_features\n","\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","    features_per_example = collections.defaultdict(list)\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","    final_predictions = postprocess_qa_predictions(val_dataset, validation_features, raw_predictions.predictions,n_best_answers,max_answer_length)\n","    metric = load_metric(\"squad\")\n","    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n","    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in val_dataset]\n","    for j in range(len(references)):\n","        wrong=True\n","        for t in references[j][\"answers\"][\"text\"]:\n","            if normalize_answer(formatted_predictions[j]['prediction_text'])==normalize_answer(t):\n","                wrong=False\n","                break\n","        if wrong:\n","            wrong_pred.append({\"id\":references[j][\"id\"],\"prediction\":formatted_predictions[j][\"prediction_text\"],\"original:\":t})\n","    return metric.compute(predictions=formatted_predictions, references=references)"]},{"cell_type":"markdown","metadata":{},"source":["### Result"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:42.028744Z","iopub.status.busy":"2022-04-10T15:03:42.028120Z","iopub.status.idle":"2022-04-10T15:04:09.035445Z","shell.execute_reply":"2022-04-10T15:04:09.034705Z","shell.execute_reply.started":"2022-04-10T15:03:42.028712Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12b147aa3037444488d37232a6100675","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"377c27dd557848c089e4879cc129a1c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Prediction *****\n","  Num examples = 144\n","  Batch size = 16\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='118' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 00:44]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Post-processing 113 example predictions split into 144 features.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dd26e667eaf44279180724e07af7fb9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86fae3284ebe49b9940a6611e5b9f2fc","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5f6ce0d44b44ed683cdd08b18281203","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["bengali : {'exact_match': 60.176991150442475, 'f1': 73.59776654024441}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aacd19c6360e423eb0753746f43bcc87","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bf71f670a8d4f629a8d68b30d77156a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Prediction *****\n","  Num examples = 786\n","  Batch size = 16\n"]},{"name":"stdout","output_type":"stream","text":["Post-processing 669 example predictions split into 786 features.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00674b35301d4875a6141fbb2a26449d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/669 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["telugu : {'exact_match': 70.254110612855, 'f1': 83.54538915367195}\n"]}],"source":["import string\n","eval_languages = [['bengali'], ['telugu']]\n","wrong_prediction={}\n","wrong_prediction['bengali']=[]\n","wrong_prediction['telugu']=[]\n","wrong_prediction['all']=[]\n","for lang in eval_languages:\n","    output = evaluate(datasets[\"validation\"],wrong_prediction[lang[0]],lang)\n","    print(lang[0],':',output)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:09.037222Z","iopub.status.busy":"2022-04-10T15:04:09.036956Z","iopub.status.idle":"2022-04-10T15:04:09.044196Z","shell.execute_reply":"2022-04-10T15:04:09.043450Z","shell.execute_reply.started":"2022-04-10T15:04:09.037186Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["wrong predictions(bengali) 45\n","wrong predictions(telugu) 199\n"]}],"source":["print('wrong predictions(bengali)',len(wrong_prediction['bengali']))\n","print('wrong predictions(telugu)',len(wrong_prediction['telugu']))"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:09.045803Z","iopub.status.busy":"2022-04-10T15:04:09.045301Z","iopub.status.idle":"2022-04-10T15:04:34.835051Z","shell.execute_reply":"2022-04-10T15:04:34.834327Z","shell.execute_reply.started":"2022-04-10T15:04:09.045749Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67458354f97546019779694fc64f2800","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f36ef2c0f3b44e09a1ecfe0f3bfd2fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Prediction *****\n","  Num examples = 930\n","  Batch size = 16\n"]},{"name":"stdout","output_type":"stream","text":["Post-processing 782 example predictions split into 930 features.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13d30217d743434ab0f3152c4c3554c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/782 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["overall {'exact_match': 68.79795396419438, 'f1': 82.10794496528662}\n"]}],"source":["output = evaluate(datasets[\"validation\"],wrong_prediction['all'],['telugu','bengali'])\n","print('overall',output)"]},{"cell_type":"markdown","metadata":{},"source":["### Visualizing wrong predictions"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:34.836659Z","iopub.status.busy":"2022-04-10T15:04:34.836408Z","iopub.status.idle":"2022-04-10T15:04:34.847016Z","shell.execute_reply":"2022-04-10T15:04:34.846240Z","shell.execute_reply.started":"2022-04-10T15:04:34.836623Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'id': 'bengali-949123041896608746-2', 'prediction': 'সোভিয়েট ইউনিয়নের কমিউনিস্ট পার্টির', 'original:': 'কমিউনিস্ট পার্টির'}\n","{'id': 'bengali-94515828498152131-10', 'prediction': '২.৪ মিলিয়ন বছর পূর্বে', 'original:': '৫০০,০০০'}\n","{'id': 'bengali-3484195517354368551-1', 'prediction': '২৯শে আগস্ট, ১৯৭১', 'original:': '১৯৭১'}\n","{'id': 'bengali--1366347128155871013-24', 'prediction': 'রাজা বরেণ্য', 'original:': 'কার্তিকেয়'}\n","{'id': 'bengali-5195671202360353215-59', 'prediction': '১৯০৫ হতে ১৯১১ খ্রীস্টাব্দ', 'original:': '১৯০৫'}\n","{'id': 'bengali--3308804124982932624-4', 'prediction': '১৯৮৬ সালের দ্বিতীয় পর্বের খেলার হোস্ট ছিল শ্রীলঙ্কা', 'original:': 'শ্রীলঙ্কা'}\n","{'id': 'bengali-8313009204852557186-4', 'prediction': 'নরেন্দ্রনাথ দত্ত', 'original:': 'বিশ্বনাথ দত্ত'}\n","{'id': 'bengali--9113522782624640859-1', 'prediction': 'চট্টগ্রাম বিশ্ববিদ্যালয়', 'original:': 'চট্টগ্রাম'}\n","{'id': 'bengali-1393909375416061787-0', 'prediction': 'বেইজিং শহর', 'original:': 'বেইজিং'}\n","{'id': 'bengali-4980664758092265474-1', 'prediction': 'ব্রহ্মা', 'original:': 'সাং চিয়েন'}\n","{'id': 'bengali-4841554072514664155-0', 'prediction': 'ইন্দিরা গান্ধী', 'original:': 'শেখ মুজিবুর রহমান'}\n","{'id': 'bengali--5802537117646660783-14', 'prediction': 'মুর্থির', 'original:': 'মুর্থি'}\n","{'id': 'bengali--3518785176444767715-2', 'prediction': 'রয়েল প্রুশিয়া', 'original:': 'রয়েল প্রুশিয়াতে'}\n","{'id': 'bengali-6674191147754665656-2', 'prediction': 'পাইওসায়ানেজ', 'original:': 'পেনিসিলিন'}\n","{'id': 'bengali--8404986622637348674-3', 'prediction': 'শ্রীলঙ্কার', 'original:': 'ভারত'}\n","{'id': 'bengali--7381837526075378596-1', 'prediction': 'চতুর্থ থেকে দ্বাদশ শতাব্দীর', 'original:': 'চতুর্থ থেকে দ্বাদশ শতাব্দী'}\n","{'id': 'bengali-8775472783303060309-15', 'prediction': 'অর্জুন', 'original:': 'অর্জুনের'}\n","{'id': 'bengali-5730130221372563642-10', 'prediction': '২৮ জুলাই', 'original:': '২০১৬ সালের ২৩ জুলাই'}\n","{'id': 'bengali--6695334746728483406-2', 'prediction': 'ঝাঁসির রানি ঝাঁসির রানির', 'original:': 'ঝাঁসির রানি'}\n","{'id': 'bengali--2660184311490318740-0', 'prediction': 'অভিজিৎ রায়', 'original:': 'মুক্তমনা'}\n","{'id': 'bengali-4524986788277724045-1', 'prediction': 'সাফা পর্বতের পাদদেশে যায়েদ-বিন-আরকামের বাড়ি', 'original:': 'সাফা পর্বতের পাদদেশে যায়েদ-বিন-আরকামের বাড়িতে'}\n","{'id': 'bengali--3707959970522014741-1', 'prediction': 'মার্কিন সশস্ত্র সৈন্য বাহিনী', 'original:': 'পারিবারিক বাড়ি'}\n","{'id': 'bengali-7443250538964255015-1', 'prediction': 'পাঁচ বছর', 'original:': 'পাঁচ'}\n","{'id': 'bengali--7623066958616917497-1', 'prediction': 'রুদ্রসাগর হ্রদের', 'original:': 'রুদ্রসাগর'}\n","{'id': 'bengali-9107229136914417048-1', 'prediction': 'হাঙ্গেরির', 'original:': 'হাঙ্গেরি'}\n","{'id': 'bengali-4667499823130888007-3', 'prediction': 'পশ্চিমবঙ্গের বীরভূম জেলার কীর্ণাহার শহরের নিকটস্থ মিরাটি গ্রামে', 'original:': 'বীরভূম'}\n","{'id': 'bengali--5315201491935714820-0', 'prediction': 'পারস্যের প্রাচীন জনগোষ্ঠীর', 'original:': 'পারস্যের প্রাচীন জনগোষ্ঠীর ভাষা'}\n","{'id': 'bengali--2223911595335362607-0', 'prediction': 'প্রাগৈতিহাসিক', 'original:': 'নব্যপ্রস্তর যুগে'}\n","{'id': 'bengali--8177010464512382506-0', 'prediction': 'আল-কিন্দি', 'original:': '৮ম থেকে ১২শ শতাব্দী'}\n","{'id': 'bengali--261227273822015974-3', 'prediction': 'যুক্তরাষ্ট্র', 'original:': 'যুক্তরাষ্ট্রের নিউ মেক্সিকো অঙ্গরাজ্যের অ্যামোগোর্দো'}\n","{'id': 'bengali-8494320032744952978-0', 'prediction': 'ফেকু ওস্তাগার লেন', 'original:': '১৩ নম্বর ফেকু ওস্তাগার লেন'}\n","{'id': 'bengali-1441381660637739676-0', 'prediction': 'যমুনা নদী', 'original:': 'যমুনা'}\n","{'id': 'bengali-7987011167425321150-3', 'prediction': 'পূর্ণিমার', 'original:': 'এ জীবন তোমার আমার'}\n","{'id': 'bengali-3279821707062003108-0', 'prediction': '২০০২ এর ৩১শে মার্চ', 'original:': '২০০২'}\n","{'id': 'bengali--1070153120447023734-5', 'prediction': 'জন', 'original:': 'নিকোলাস'}\n","{'id': 'bengali-5988277494911723032-0', 'prediction': 'তৎকালীন কুমিল্লা জেলার অধীনে ব্রাহ্মণবাড়ীয়া মহকুমার গোকর্ণঘাট গ্রাম', 'original:': 'কুমিল্লা জেলার অধীনে ব্রাহ্মণবাড়ীয়া মহকুমার গোকর্ণঘাট'}\n","{'id': 'bengali--204832994876246663-3', 'prediction': 'গৌরমোহন মুখোপাধ্যায় স্ট্রিটে', 'original:': 'উত্তর কলকাতার'}\n","{'id': 'bengali-4465126415643560051-0', 'prediction': 'আগুন', 'original:': 'তামাক'}\n","{'id': 'bengali--1538257118875639863-2', 'prediction': '১৮৭০', 'original:': '১৮৭০ সালে ২২শে এপ্রিল'}\n","{'id': 'bengali--8867696482683155680-0', 'prediction': 'ঢাকা বিভাগের অন্তর্গত টাঙ্গাইলের', 'original:': 'ঢাকা বিভাগের অন্তর্গত টাঙ্গাইলের সন্তোষে'}\n"]}],"source":["picks = random.sample(range(0, len(wrong_prediction['bengali'])-1), min(40,len(wrong_prediction['bengali'])-1))\n","for i in picks:\n","    print(wrong_prediction['bengali'][i])"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:34.848465Z","iopub.status.busy":"2022-04-10T15:04:34.848221Z","iopub.status.idle":"2022-04-10T15:04:34.862329Z","shell.execute_reply":"2022-04-10T15:04:34.861655Z","shell.execute_reply.started":"2022-04-10T15:04:34.848431Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'id': 'telugu-227033373636002222-1', 'prediction': '168 హెక్టార్లలో', 'original:': '168 హెక్టార్ల'}\n","{'id': 'telugu-675854620814783374-15', 'prediction': 'సేమా గ్రూప్', 'original:': 'వోడా ఫోన్'}\n","{'id': 'telugu--7150452250756477828-2', 'prediction': '490 హెక్టార్లలో', 'original:': '490 హెక్టార్ల'}\n","{'id': 'telugu-8243050460142458655-0', 'prediction': '1961 హెక్టార్లలో', 'original:': '1961 హెక్టార్ల'}\n","{'id': 'telugu-8129278576030709234-0', 'prediction': 'తూర్పు గోదావరి జిల్లా', 'original:': 'తూర్పు గోదావరి'}\n","{'id': 'telugu-2983175149020114154-5', 'prediction': 'అన్ అర్బోర్, మిచిగాన్', 'original:': 'అన్ అర్బోర్, మిచిగాన్\\u200c'}\n","{'id': 'telugu-9115912749184044385-1', 'prediction': 'నెదర్లాండ్', 'original:': 'పశ్చిమ ఆఫ్ఘనిస్థాన్\\u200c'}\n","{'id': 'telugu--2073283125164763733-0', 'prediction': '39 హెక్టార్లలో', 'original:': '39 హెక్టార్ల'}\n","{'id': 'telugu-8253928922712570370-4', 'prediction': '310 హెక్టార్లలో', 'original:': '310 హెక్టార్ల'}\n","{'id': 'telugu-4831434226867109360-7', 'prediction': '1915 నవంబర్ 30', 'original:': '53'}\n","{'id': 'telugu-5315675774639248518-0', 'prediction': 'పాకిస్తాన్', 'original:': 'భారతదేశం'}\n","{'id': 'telugu-8419414583131587883-0', 'prediction': '1011 హెక్టార్లలో', 'original:': '1011 హెక్టార్ల'}\n","{'id': 'telugu--8810693408625259944-0', 'prediction': '153 హెక్టార్లలో', 'original:': '153 హెక్టార్ల'}\n","{'id': 'telugu-512134417162412789-15', 'prediction': 'బ్రూనై ఇంటర్నేషనల్ విమానాశ్రయము', 'original:': 'బ్రునై డాలర్లు'}\n","{'id': 'telugu--3272466605711022131-2', 'prediction': '2,623', 'original:': '2704'}\n","{'id': 'telugu-2355058992665135572-0', 'prediction': '198 హెక్టార్లలో', 'original:': '198 హెక్టార్ల'}\n","{'id': 'telugu-918133519643966911-0', 'prediction': 'పూణే', 'original:': 'పూణే, మహారాష్ట్ర'}\n","{'id': 'telugu-4527046517267694248-0', 'prediction': '1179 హెక్టార్లలో', 'original:': '1179 హెక్టార్ల'}\n","{'id': 'telugu-7280221406834583430-1', 'prediction': 'అలి గడ్\\u200cలో', 'original:': 'ఢిల్లి'}\n","{'id': 'telugu-3854057866257069688-1', 'prediction': 'పుదువసంతం', 'original:': 'పురియాద పుధిర్'}\n","{'id': 'telugu--9052359011095805857-3', 'prediction': '2324 హెక్టార్లలో', 'original:': '2324 హెక్టార్ల'}\n","{'id': 'telugu--5004400969238813453-0', 'prediction': '190 హెక్టార్లలో', 'original:': '190 హెక్టార్ల'}\n","{'id': 'telugu-1327025946082456622-4', 'prediction': 'ఉల్లమ్ కెట్కుమాయే', 'original:': 'అరినుథమ్ అరియమలుమ్(2005)'}\n","{'id': 'telugu--534530456931366482-0', 'prediction': '2269 హెక్టార్లలో', 'original:': '2269 హెక్టార్ల'}\n","{'id': 'telugu--397999538407153813-1', 'prediction': 'సాహెబ్\\u200cబీ, మదార్\\u200cసాబ్', 'original:': 'మదార్\\u200cసాబ్'}\n","{'id': 'telugu--530661135137008399-0', 'prediction': '816 హెక్టార్లలో', 'original:': '816 హెక్టార్ల'}\n","{'id': 'telugu--1626927074160241543-0', 'prediction': '28 హెక్టార్లలో', 'original:': '28 హెక్టార్ల'}\n","{'id': 'telugu--3316938560622730206-1', 'prediction': 'రాజయ్యశాస్త్రి మరియు సుచేత', 'original:': 'రాజయ్యశాస్త్రి'}\n","{'id': 'telugu--6140267610656239828-1', 'prediction': '15 హెక్టార్లలో', 'original:': '15 హెక్టార్ల'}\n","{'id': 'telugu--3406235526541671609-0', 'prediction': '671 హెక్టార్లలో', 'original:': '671 హెక్టార్ల'}\n","{'id': 'telugu--4099819279895685485-0', 'prediction': '23 హెక్టార్లలో', 'original:': '23 హెక్టార్ల'}\n","{'id': 'telugu-2788352386131681213-2', 'prediction': 'డార్లెనె టోనాచియో మరియు ఫ్రాంక్లిన్ ఫాక్స్', 'original:': 'డార్లెనె టోనాచియో'}\n","{'id': 'telugu--548921703247702173-0', 'prediction': '736 హెక్టార్లలో', 'original:': '736 హెక్టార్ల'}\n","{'id': 'telugu--4139417899306970261-0', 'prediction': '0 హెక్టార్లలో', 'original:': '0 హెక్టార్ల'}\n","{'id': 'telugu-4617795002680831857-1', 'prediction': '14వ శతాబ్దం', 'original:': '14వ శతాబ్దంలో'}\n","{'id': 'telugu--4733237526728225686-2', 'prediction': '1954 హెక్టార్లలో', 'original:': '1954 హెక్టార్ల'}\n","{'id': 'telugu--4536152537674333130-3', 'prediction': 'బెట్టీ', 'original:': 'ఎలిజబెత్ \"బెట్టీ\" అగస్సీ'}\n","{'id': 'telugu--4625427927478601702-1', 'prediction': 'కొంకుదురు', 'original:': 'తూర్పు గోదావరి జిల్లా రామచంద్రపురం తాలూకా అనపర్తి నియోజక వర్గంలోని బిక్కవోలు మండంలో ఉన్న  కొంకుదురు'}\n","{'id': 'telugu-4078824087382361401-17', 'prediction': 'కొంకణ్ తీరభూమి', 'original:': 'తమ్హిని ఘాట్, వరంధ ఘాట్, సవంత్\\u200cవాడి ఘాట్'}\n","{'id': 'telugu-5457773759727946591-0', 'prediction': '2002 -2005 మధ్య', 'original:': '2002'}\n"]}],"source":["picks = random.sample(range(0, len(wrong_prediction['telugu'])-1), min(40,len(wrong_prediction['telugu'])-1))\n","for i in picks:\n","    print(wrong_prediction['telugu'][i])"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:34.864193Z","iopub.status.busy":"2022-04-10T15:04:34.863822Z","iopub.status.idle":"2022-04-10T15:06:22.354622Z","shell.execute_reply":"2022-04-10T15:06:22.353742Z","shell.execute_reply.started":"2022-04-10T15:04:34.864033Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bert-base-multilingual-cased-finetuned-model\n","Configuration saved in bert-base-multilingual-cased-finetuned-model/config.json\n","Model weights saved in bert-base-multilingual-cased-finetuned-model/pytorch_model.bin\n","tokenizer config file saved in bert-base-multilingual-cased-finetuned-model/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-finetuned-model/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f82317213cb045b4920f9192cd7a20f2","version_major":2,"version_minor":0},"text/plain":["Upload file pytorch_model.bin:   0%|          | 32.0k/676M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e58847f59d34bb097ed0c1b9fb9fde7","version_major":2,"version_minor":0},"text/plain":["Upload file training_args.bin: 100%|##########| 3.05k/3.05k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7aad07d8d51c444a8773abc7e90f6901","version_major":2,"version_minor":0},"text/plain":["Upload file runs/Apr10_12-44-43_1ea24f5b9b85/1649594696.080163/events.out.tfevents.1649594696.1ea24f5b9b85.34.…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f34840574c648a683c1e29f3e6a8947","version_major":2,"version_minor":0},"text/plain":["Upload file runs/Apr10_12-44-43_1ea24f5b9b85/events.out.tfevents.1649594696.1ea24f5b9b85.34.0: 100%|##########…"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["To https://huggingface.co/krinal214/bert-all-squad_ben_tel_context\n","   3e9b6a8..d88841d  main -> main\n","\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["To https://huggingface.co/krinal214/bert-all-squad_ben_tel_context\n","   d88841d..64cbb44  main -> main\n","\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"text/plain":["'https://huggingface.co/krinal214/bert-all-squad_ben_tel_context/commit/d88841dd62e28f8013a540a51142c596bcf6794b'"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["#trainer.push_to_hub()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
