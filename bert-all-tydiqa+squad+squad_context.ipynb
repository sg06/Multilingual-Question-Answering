{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:38:11.776940Z","iopub.status.busy":"2022-04-10T12:38:11.774416Z","iopub.status.idle":"2022-04-10T12:38:35.489717Z","shell.execute_reply":"2022-04-10T12:38:35.488851Z","shell.execute_reply.started":"2022-04-10T12:38:11.776897Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.16.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.11.6)\n","Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.49)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.26.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.18.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.4.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.62.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.20.3)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.26.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.2.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.3)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.6)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.4.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.26.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (21.3)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.11.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.1.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.62.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface_hub) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.7)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["! pip install transformers \n","! pip install datasets \n","! pip install huggingface_hub"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:38:58.789098Z","iopub.status.busy":"2022-04-10T12:38:58.788312Z","iopub.status.idle":"2022-04-10T12:38:58.873346Z","shell.execute_reply":"2022-04-10T12:38:58.872690Z","shell.execute_reply.started":"2022-04-10T12:38:58.789060Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c04416e8b174c6ab24528be78b4e3cb","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["#from huggingface_hub import notebook_login\n","\n","#notebook_login()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.405388Z","iopub.status.busy":"2022-04-10T12:39:06.405084Z","iopub.status.idle":"2022-04-10T12:39:06.409459Z","shell.execute_reply":"2022-04-10T12:39:06.408724Z","shell.execute_reply.started":"2022-04-10T12:39:06.405345Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.420026Z","iopub.status.busy":"2022-04-10T12:39:06.419684Z","iopub.status.idle":"2022-04-10T12:39:06.477740Z","shell.execute_reply":"2022-04-10T12:39:06.476986Z","shell.execute_reply.started":"2022-04-10T12:39:06.419996Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.16.2\n"]}],"source":["import transformers\n","print(transformers.__version__)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.479711Z","iopub.status.busy":"2022-04-10T12:39:06.479443Z","iopub.status.idle":"2022-04-10T12:39:06.483753Z","shell.execute_reply":"2022-04-10T12:39:06.482845Z","shell.execute_reply.started":"2022-04-10T12:39:06.479668Z"},"trusted":true},"outputs":[],"source":["model_checkpoint = \"bert-base-multilingual-cased\"\n","batch_size = 16"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:06.485841Z","iopub.status.busy":"2022-04-10T12:39:06.484904Z","iopub.status.idle":"2022-04-10T12:39:12.854891Z","shell.execute_reply":"2022-04-10T12:39:12.854026Z","shell.execute_reply.started":"2022-04-10T12:39:06.485764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  git-lfs\n","0 upgraded, 1 newly installed, 0 to remove and 75 not upgraded.\n","Need to get 3316 kB of archives.\n","After this operation, 11.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\n","Fetched 3316 kB in 2s (2114 kB/s)  \u001b[0m33m\u001b[33m\u001b[33m\n","\n","\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\n","(Reading database ... 103274 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\n","\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\n","\n","\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"]}],"source":["# !apt install git-lfs\n","# !git config --global user.email \"patelkrinal214@gmail.com\"\n","# !git config --global user.name \"krinal214\""]},{"cell_type":"markdown","metadata":{},"source":["### Loading the dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:12.857515Z","iopub.status.busy":"2022-04-10T12:39:12.857293Z","iopub.status.idle":"2022-04-10T12:39:13.290649Z","shell.execute_reply":"2022-04-10T12:39:13.289831Z","shell.execute_reply.started":"2022-04-10T12:39:12.857490Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset, load_metric"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:39:13.294576Z","iopub.status.busy":"2022-04-10T12:39:13.294357Z","iopub.status.idle":"2022-04-10T12:41:16.403445Z","shell.execute_reply":"2022-04-10T12:41:16.402677Z","shell.execute_reply.started":"2022-04-10T12:39:13.294538Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6691890a9194cc691d958578744531b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/3.49k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36481865ffdb43bc93fe9bc22a522bb9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset tydiqa/secondary_task (download: 1.82 GiB, generated: 55.27 MiB, post-processed: Unknown size, total: 1.87 GiB) to /root/.cache/huggingface/datasets/tydiqa/secondary_task/1.0.0/b8a6c4c0db10bf5703d7b36645e5dbae821b8c0e902dac9daeecd459a8337148...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42cc400a865a43c89646ab085cf33a02","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92e0cf1f69784f2c8cd7f7fc0b173739","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"622ce2bd652c4fe4ad88c37cdcb7e85f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/161M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"620264eb2ede41a797ba9f85d448e30a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"035728ae73e345c5bdff3b6269f3451a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1adfa65280d54691880a1dd4f8e3859c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/58.0M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"594b20065c834a26b00924694772798d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/5.62M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b2bc904c2a14a329308c3d2c94fc399","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset tydiqa downloaded and prepared to /root/.cache/huggingface/datasets/tydiqa/secondary_task/1.0.0/b8a6c4c0db10bf5703d7b36645e5dbae821b8c0e902dac9daeecd459a8337148. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1c867f6fdfb4c85b09b9ce590b83ea6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 49881\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 5077\n","    })\n","})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["datasets=load_dataset(\"tydiqa\",\"secondary_task\")\n","datasets"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:16.405624Z","iopub.status.busy":"2022-04-10T12:41:16.404752Z","iopub.status.idle":"2022-04-10T12:41:24.098638Z","shell.execute_reply":"2022-04-10T12:41:24.097861Z","shell.execute_reply.started":"2022-04-10T12:41:16.405587Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec6f106bc69940a6ad50ea67fc24d1ea","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/default (download: 20.08 MiB, generated: 50.65 MiB, post-processed: Unknown size, total: 70.73 MiB) to /root/.cache/huggingface/datasets/parquet/krinal214--squad_ben_tel_context-44f016df634c4eda/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ad109c7f3e845db843bea024f449c34","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"499c36451b8c44fdb62a69df28223358","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.70M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d77721585674fe4b94c4961c96eef7e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/15.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5b3ce2420da4bc5b5df4aae01a38666","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/3.61M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52a9a5aec99048e6bd2f2a52b308d8b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/krinal214--squad_ben_tel_context-44f016df634c4eda/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eec8a574f8c64e63a8fb569c2fb13deb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset1=load_dataset('krinal214/squad_ben_tel_context')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:24.100819Z","iopub.status.busy":"2022-04-10T12:41:24.100251Z","iopub.status.idle":"2022-04-10T12:41:24.107231Z","shell.execute_reply":"2022-04-10T12:41:24.106223Z","shell.execute_reply.started":"2022-04-10T12:41:24.100761Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    test: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 7880\n","    })\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 57070\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 14301\n","    })\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["dataset1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:24.109611Z","iopub.status.busy":"2022-04-10T12:41:24.109015Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73ac75c1377342cca1a6af04298e5730","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aacc56cb37a248ca90ea6bbd2ab5df0d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7373697d3af423394aab7c5a914085c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3dadd273b4ae47268916d36a2ed67230","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a079f22fc2f4592bc3b8b8b2fc7f25e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb35bf3b9f6c4dd1ac6574175d1c4ad9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"999eef48bf2d4e1e935eaeff4e58ccdc","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset2=load_dataset('squad')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import concatenate_datasets\n","datasets['train']=concatenate_datasets([datasets['train'],dataset1['train']])\n","datasets['train']=concatenate_datasets([datasets['train'],dataset2['train']])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import re\n","def filter_dataset(ds,lang):\n","    def check(d):\n","        for i in lang:\n","            if re.search(i,d):\n","                return True\n","        return False\n","    ds = ds.filter(lambda x: check(x['id']))\n","    return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import ClassLabel, Sequence\n","import random\n","import pandas as pd\n","from IPython.display import display, HTML\n","\n","\n","def show_random_elements(dataset, num_examples=8):\n","    picks = random.sample(range(0, len(dataset)-1), num_examples)\n","    df = pd.DataFrame(dataset[picks])\n","    display(HTML(df.to_html()))"]},{"cell_type":"markdown","metadata":{},"source":["### Preparing the training and validation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# datasets[\"train\"]=filter_dataset(datasets[\"validation\"],['bengali'])\n","datasets[\"validation\"]=filter_dataset(datasets[\"validation\"],['bengali', 'telugu'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["show_random_elements(datasets[\"train\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["max_length = 384  # The maximum length of a feature (question and context)\n","doc_stride = 160  # The allowed overlap between two part of the context when splitting is performed."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.status.idle":"2022-04-10T12:41:48.702350Z","shell.execute_reply":"2022-04-10T12:41:48.701697Z","shell.execute_reply.started":"2022-04-10T12:41:42.997337Z"},"trusted":true},"outputs":[],"source":["datasets['train']=datasets['train'].filter(lambda example: len(example['question'])<=max_length)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:48.703917Z","iopub.status.busy":"2022-04-10T12:41:48.703635Z","iopub.status.idle":"2022-04-10T12:41:48.708431Z","shell.execute_reply":"2022-04-10T12:41:48.707750Z","shell.execute_reply.started":"2022-04-10T12:41:48.703881Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 194549\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers'],\n","        num_rows: 782\n","    })\n","})\n"]}],"source":["print(datasets)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:48.711548Z","iopub.status.busy":"2022-04-10T12:41:48.711139Z","iopub.status.idle":"2022-04-10T12:41:48.734854Z","shell.execute_reply":"2022-04-10T12:41:48.733925Z","shell.execute_reply.started":"2022-04-10T12:41:48.711513Z"},"trusted":true},"outputs":[],"source":["def prepare_train_features(examples):\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","    tokenized_examples = tokenizer(\n","        examples[\"question\"],\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n","\n","    # Let's label those examples!\n","    tokenized_examples[\"start_positions\"] = []\n","    tokenized_examples[\"end_positions\"] = []\n","\n","    for i, offsets in enumerate(offset_mapping):\n","        # We will label impossible answers with the index of the CLS token.\n","        input_ids = tokenized_examples[\"input_ids\"][i]\n","        cls_index = input_ids.index(tokenizer.cls_token_id)\n","\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        answers = examples[\"answers\"][sample_index]\n","        # If no answers are given, set the cls_index as answer.\n","        if len(answers[\"answer_start\"]) == 0:\n","            tokenized_examples[\"start_positions\"].append(cls_index)\n","            tokenized_examples[\"end_positions\"].append(cls_index)\n","        else:\n","            # Start/end character index of the answer in the text.\n","            start_char = answers[\"answer_start\"][0]\n","            end_char = start_char + len(answers[\"text\"][0])\n","\n","            # Start token index of the current span in the text.\n","            token_start_index = 0\n","            while sequence_ids[token_start_index] != 1 :\n","                token_start_index += 1\n","\n","            # End token index of the current span in the text.\n","            token_end_index = len(input_ids) - 1\n","            while sequence_ids[token_end_index] != 1:\n","                token_end_index -= 1\n","    \n","            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n","            if not (\n","                offsets[token_start_index][0] <= start_char\n","                and offsets[token_end_index][1] >= end_char\n","            ):\n","                tokenized_examples[\"start_positions\"].append(cls_index)\n","                tokenized_examples[\"end_positions\"].append(cls_index)\n","            else:\n","                while (\n","                    token_start_index < len(offsets)\n","                    and offsets[token_start_index][0] <= start_char\n","                ):\n","                    token_start_index += 1\n","                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n","\n","    return tokenized_examples"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:41:48.736657Z","iopub.status.busy":"2022-04-10T12:41:48.736158Z","iopub.status.idle":"2022-04-10T12:44:18.890727Z","shell.execute_reply":"2022-04-10T12:44:18.890035Z","shell.execute_reply.started":"2022-04-10T12:41:48.736621Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"786386453bab456fa668d38b7aa59193","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/195 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0adef2c76d742db91464f61fef4e3d7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = datasets.map(\n","    prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:18.892339Z","iopub.status.busy":"2022-04-10T12:44:18.892002Z","iopub.status.idle":"2022-04-10T12:44:37.578336Z","shell.execute_reply":"2022-04-10T12:44:37.577682Z","shell.execute_reply.started":"2022-04-10T12:44:18.892301Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db131ac72c8a46d5b06ddf4714bb0701","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForQuestionAnswering\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:37.579899Z","iopub.status.busy":"2022-04-10T12:44:37.579553Z","iopub.status.idle":"2022-04-10T12:44:43.451871Z","shell.execute_reply":"2022-04-10T12:44:43.451084Z","shell.execute_reply.started":"2022-04-10T12:44:37.579860Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","/opt/conda/lib/python3.7/site-packages/transformers/training_args.py:951: FutureWarning: `--push_to_hub_model_id` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_model_id` instead and pass the full repo name to this argument (in this case krinal214/bert-all-squad_ben_tel_context).\n","  FutureWarning,\n"]}],"source":["from transformers import TrainingArguments, Trainer\n","model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    f\"{model_name}-finetuned-model\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=1,\n","    weight_decay=0.01,\n","    #push_to_hub = True,\n","    #push_to_hub_model_id = \"bert-all-squad_ben_tel_context\",\n","    save_steps=50000\n",")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:43.453736Z","iopub.status.busy":"2022-04-10T12:44:43.453306Z","iopub.status.idle":"2022-04-10T12:44:43.457735Z","shell.execute_reply":"2022-04-10T12:44:43.457057Z","shell.execute_reply.started":"2022-04-10T12:44:43.453687Z"},"trusted":true},"outputs":[],"source":["from transformers import DefaultDataCollator\n","\n","data_collator = DefaultDataCollator()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:43.459377Z","iopub.status.busy":"2022-04-10T12:44:43.458901Z","iopub.status.idle":"2022-04-10T12:44:56.009560Z","shell.execute_reply":"2022-04-10T12:44:56.008681Z","shell.execute_reply.started":"2022-04-10T12:44:43.459341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["Cloning https://huggingface.co/krinal214/bert-all-squad_ben_tel_context into local empty directory.\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:56.011713Z","iopub.status.busy":"2022-04-10T12:44:56.011435Z","iopub.status.idle":"2022-04-10T12:44:56.016711Z","shell.execute_reply":"2022-04-10T12:44:56.016006Z","shell.execute_reply.started":"2022-04-10T12:44:56.011667Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","        num_rows: 202801\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","        num_rows: 930\n","    })\n","})\n"]}],"source":["print(tokenized_datasets)"]},{"cell_type":"markdown","metadata":{},"source":["### Training the model"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T12:44:56.018619Z","iopub.status.busy":"2022-04-10T12:44:56.018149Z","iopub.status.idle":"2022-04-10T15:03:41.957136Z","shell.execute_reply":"2022-04-10T15:03:41.956441Z","shell.execute_reply.started":"2022-04-10T12:44:56.018582Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 202801\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 12676\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='12676' max='12676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12676/12676 2:18:44, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.996000</td>\n","      <td>0.539258</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 930\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=12676, training_loss=1.1739939421499967, metrics={'train_runtime': 8325.8954, 'train_samples_per_second': 24.358, 'train_steps_per_second': 1.522, 'total_flos': 3.974343267211315e+16, 'train_loss': 1.1739939421499967, 'epoch': 1.0})"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:41.958870Z","iopub.status.busy":"2022-04-10T15:03:41.958516Z","iopub.status.idle":"2022-04-10T15:03:41.969235Z","shell.execute_reply":"2022-04-10T15:03:41.968505Z","shell.execute_reply.started":"2022-04-10T15:03:41.958833Z"},"trusted":true},"outputs":[],"source":["def prepare_validation_features(examples):\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","\n","    \n","    tokenized_examples = tokenizer(\n","        examples[\"question\"],\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    \n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","\n","    # We keep the example_id that gave us this feature and we will store the offset mappings.\n","    tokenized_examples[\"example_id\"] = []\n","\n","    for i in range(len(tokenized_examples[\"input_ids\"])):\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","        context_index = 1 \n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n","\n","        tokenized_examples[\"offset_mapping\"][i] = [\n","            (o if sequence_ids[k] == context_index else None)\n","            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n","        ]\n","\n","    return tokenized_examples"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluating the model"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:41.974512Z","iopub.status.busy":"2022-04-10T15:03:41.973937Z","iopub.status.idle":"2022-04-10T15:03:41.986334Z","shell.execute_reply":"2022-04-10T15:03:41.985482Z","shell.execute_reply.started":"2022-04-10T15:03:41.974467Z"},"trusted":true},"outputs":[],"source":["max_answer_length = 50\n","n_best_answers=20"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:41.988845Z","iopub.status.busy":"2022-04-10T15:03:41.988483Z","iopub.status.idle":"2022-04-10T15:03:42.008073Z","shell.execute_reply":"2022-04-10T15:03:42.007010Z","shell.execute_reply.started":"2022-04-10T15:03:41.988805Z"},"trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","import numpy as np\n","\n","def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 50):\n","    all_start_logits, all_end_logits = raw_predictions\n","    # Build a map example to its corresponding features.\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","    features_per_example = collections.defaultdict(list)\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","    predictions = collections.OrderedDict()\n","    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n","\n","    # Let's loop over all the examples!\n","    for example_index, example in enumerate(tqdm(examples)):\n","        # Those are the indices of the features associated to the current example.\n","        feature_indices = features_per_example[example_index]\n","\n","        min_null_score = None # Only used if squad_v2 is True.\n","        valid_answers = []\n","        \n","        context = example[\"context\"]\n","        # Looping through all the features associated to the current example.\n","        for feature_index in feature_indices:\n","            # We grab the predictions of the model for this feature.\n","            start_logits = all_start_logits[feature_index]\n","            end_logits = all_end_logits[feature_index]\n","            # This is what will allow us to map some the positions in our logits to span of texts in the original\n","            # context.\n","            offset_mapping = features[feature_index][\"offset_mapping\"]\n","\n","            # Update minimum null prediction.\n","            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n","            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n","            if min_null_score is None or min_null_score < feature_null_score:\n","                min_null_score = feature_null_score\n","\n","            # Go through all possibilities for the `n_best_size` greater start and end logits.\n","            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n","                    # to part of the input_ids that are not in the context.\n","                    if (\n","                        start_index >= len(offset_mapping)\n","                        or end_index >= len(offset_mapping)\n","                        or offset_mapping[start_index] is None\n","                        or offset_mapping[end_index] is None\n","                        or len(offset_mapping[start_index])==0\n","                        or len(offset_mapping[end_index])==0\n","                    ):\n","                        continue\n","                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n","                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n","                        continue\n","\n","                    try:\n","                        start_char = offset_mapping[start_index][0]\n","                        end_char = offset_mapping[end_index][1]\n","                        valid_answers.append(\n","                            {\n","                                \"score\": start_logits[start_index] + end_logits[end_index],\n","                                \"text\": context[start_char: end_char]\n","                            }\n","                        )\n","                    except IndexError:\n","                        continue\n","\n","        \n","        if len(valid_answers) > 0:\n","            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n","        else:\n","            best_answer = {\"text\": \"\", \"score\": 0.0}\n","        \n","        predictions[example[\"id\"]] = best_answer[\"text\"]\n","        \n","    return predictions\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:42.010519Z","iopub.status.busy":"2022-04-10T15:03:42.009690Z","iopub.status.idle":"2022-04-10T15:03:42.024916Z","shell.execute_reply":"2022-04-10T15:03:42.024128Z","shell.execute_reply.started":"2022-04-10T15:03:42.010477Z"},"trusted":true},"outputs":[],"source":["import collections\n","def evaluate(ds,wrong_pred,language):\n","    val_dataset=filter_dataset(ds,language)\n","    validation_features = val_dataset.map(\n","        prepare_validation_features,\n","        batched=True,\n","        remove_columns=val_dataset.column_names\n","    )\n","    raw_predictions = trainer.predict(validation_features)\n","    validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n","    \n","    examples = val_dataset\n","    features = validation_features\n","\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","    features_per_example = collections.defaultdict(list)\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","    final_predictions = postprocess_qa_predictions(val_dataset, validation_features, raw_predictions.predictions,n_best_answers,max_answer_length)\n","    metric = load_metric(\"squad\")\n","    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n","    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in val_dataset]\n","    for j in range(len(references)):\n","        wrong=True\n","        for t in references[j][\"answers\"][\"text\"]:\n","            if normalize_answer(formatted_predictions[j]['prediction_text'])==normalize_answer(t):\n","                wrong=False\n","                break\n","        if wrong:\n","            wrong_pred.append({\"id\":references[j][\"id\"],\"prediction\":formatted_predictions[j][\"prediction_text\"],\"original:\":t})\n","    return metric.compute(predictions=formatted_predictions, references=references)"]},{"cell_type":"markdown","metadata":{},"source":["### Result"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:03:42.028744Z","iopub.status.busy":"2022-04-10T15:03:42.028120Z","iopub.status.idle":"2022-04-10T15:04:09.035445Z","shell.execute_reply":"2022-04-10T15:04:09.034705Z","shell.execute_reply.started":"2022-04-10T15:03:42.028712Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12b147aa3037444488d37232a6100675","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"377c27dd557848c089e4879cc129a1c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Prediction *****\n","  Num examples = 144\n","  Batch size = 16\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='118' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 00:44]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Post-processing 113 example predictions split into 144 features.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dd26e667eaf44279180724e07af7fb9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86fae3284ebe49b9940a6611e5b9f2fc","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5f6ce0d44b44ed683cdd08b18281203","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["bengali : {'exact_match': 60.176991150442475, 'f1': 73.59776654024441}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aacd19c6360e423eb0753746f43bcc87","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bf71f670a8d4f629a8d68b30d77156a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Prediction *****\n","  Num examples = 786\n","  Batch size = 16\n"]},{"name":"stdout","output_type":"stream","text":["Post-processing 669 example predictions split into 786 features.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00674b35301d4875a6141fbb2a26449d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/669 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["telugu : {'exact_match': 70.254110612855, 'f1': 83.54538915367195}\n"]}],"source":["import string\n","eval_languages = [['bengali'], ['telugu']]\n","wrong_prediction={}\n","wrong_prediction['bengali']=[]\n","wrong_prediction['telugu']=[]\n","wrong_prediction['all']=[]\n","for lang in eval_languages:\n","    output = evaluate(datasets[\"validation\"],wrong_prediction[lang[0]],lang)\n","    print(lang[0],':',output)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:09.037222Z","iopub.status.busy":"2022-04-10T15:04:09.036956Z","iopub.status.idle":"2022-04-10T15:04:09.044196Z","shell.execute_reply":"2022-04-10T15:04:09.043450Z","shell.execute_reply.started":"2022-04-10T15:04:09.037186Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["wrong predictions(bengali) 45\n","wrong predictions(telugu) 199\n"]}],"source":["print('wrong predictions(bengali)',len(wrong_prediction['bengali']))\n","print('wrong predictions(telugu)',len(wrong_prediction['telugu']))"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:09.045803Z","iopub.status.busy":"2022-04-10T15:04:09.045301Z","iopub.status.idle":"2022-04-10T15:04:34.835051Z","shell.execute_reply":"2022-04-10T15:04:34.834327Z","shell.execute_reply.started":"2022-04-10T15:04:09.045749Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67458354f97546019779694fc64f2800","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f36ef2c0f3b44e09a1ecfe0f3bfd2fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n","***** Running Prediction *****\n","  Num examples = 930\n","  Batch size = 16\n"]},{"name":"stdout","output_type":"stream","text":["Post-processing 782 example predictions split into 930 features.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13d30217d743434ab0f3152c4c3554c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/782 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["overall {'exact_match': 68.79795396419438, 'f1': 82.10794496528662}\n"]}],"source":["output = evaluate(datasets[\"validation\"],wrong_prediction['all'],['telugu','bengali'])\n","print('overall',output)"]},{"cell_type":"markdown","metadata":{},"source":["### Visualizing wrong predictions"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:34.836659Z","iopub.status.busy":"2022-04-10T15:04:34.836408Z","iopub.status.idle":"2022-04-10T15:04:34.847016Z","shell.execute_reply":"2022-04-10T15:04:34.846240Z","shell.execute_reply.started":"2022-04-10T15:04:34.836623Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'id': 'bengali-949123041896608746-2', 'prediction': 'à¦¸à§‹à¦­à¦¿à¦¯à¦¼à§‡à¦Ÿ à¦‡à¦‰à¦¨à¦¿à¦¯à¦¼à¦¨à§‡à¦° à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦¸à§à¦Ÿ à¦ªà¦¾à¦°à§à¦Ÿà¦¿à¦°', 'original:': 'à¦•à¦®à¦¿à¦‰à¦¨à¦¿à¦¸à§à¦Ÿ à¦ªà¦¾à¦°à§à¦Ÿà¦¿à¦°'}\n","{'id': 'bengali-94515828498152131-10', 'prediction': 'à§¨.à§ª à¦®à¦¿à¦²à¦¿à¦¯à¦¼à¦¨ à¦¬à¦›à¦° à¦ªà§‚à¦°à§à¦¬à§‡', 'original:': 'à§«à§¦à§¦,à§¦à§¦à§¦'}\n","{'id': 'bengali-3484195517354368551-1', 'prediction': 'à§¨à§¯à¦¶à§‡ à¦†à¦—à¦¸à§à¦Ÿ, à§§à§¯à§­à§§', 'original:': 'à§§à§¯à§­à§§'}\n","{'id': 'bengali--1366347128155871013-24', 'prediction': 'à¦°à¦¾à¦œà¦¾ à¦¬à¦°à§‡à¦£à§à¦¯', 'original:': 'à¦•à¦¾à¦°à§à¦¤à¦¿à¦•à§‡à¦¯à¦¼'}\n","{'id': 'bengali-5195671202360353215-59', 'prediction': 'à§§à§¯à§¦à§« à¦¹à¦¤à§‡ à§§à§¯à§§à§§ à¦–à§à¦°à§€à¦¸à§à¦Ÿà¦¾à¦¬à§à¦¦', 'original:': 'à§§à§¯à§¦à§«'}\n","{'id': 'bengali--3308804124982932624-4', 'prediction': 'à§§à§¯à§®à§¬ à¦¸à¦¾à¦²à§‡à¦° à¦¦à§à¦¬à¦¿à¦¤à§€à¦¯à¦¼ à¦ªà¦°à§à¦¬à§‡à¦° à¦–à§‡à¦²à¦¾à¦° à¦¹à§‹à¦¸à§à¦Ÿ à¦›à¦¿à¦² à¦¶à§à¦°à§€à¦²à¦™à§à¦•à¦¾', 'original:': 'à¦¶à§à¦°à§€à¦²à¦™à§à¦•à¦¾'}\n","{'id': 'bengali-8313009204852557186-4', 'prediction': 'à¦¨à¦°à§‡à¦¨à§à¦¦à§à¦°à¦¨à¦¾à¦¥ à¦¦à¦¤à§à¦¤', 'original:': 'à¦¬à¦¿à¦¶à§à¦¬à¦¨à¦¾à¦¥ à¦¦à¦¤à§à¦¤'}\n","{'id': 'bengali--9113522782624640859-1', 'prediction': 'à¦šà¦Ÿà§à¦Ÿà¦—à§à¦°à¦¾à¦® à¦¬à¦¿à¦¶à§à¦¬à¦¬à¦¿à¦¦à§à¦¯à¦¾à¦²à¦¯à¦¼', 'original:': 'à¦šà¦Ÿà§à¦Ÿà¦—à§à¦°à¦¾à¦®'}\n","{'id': 'bengali-1393909375416061787-0', 'prediction': 'à¦¬à§‡à¦‡à¦œà¦¿à¦‚ à¦¶à¦¹à¦°', 'original:': 'à¦¬à§‡à¦‡à¦œà¦¿à¦‚'}\n","{'id': 'bengali-4980664758092265474-1', 'prediction': 'à¦¬à§à¦°à¦¹à§à¦®à¦¾', 'original:': 'à¦¸à¦¾à¦‚ à¦šà¦¿à¦¯à¦¼à§‡à¦¨'}\n","{'id': 'bengali-4841554072514664155-0', 'prediction': 'à¦‡à¦¨à§à¦¦à¦¿à¦°à¦¾ à¦—à¦¾à¦¨à§à¦§à§€', 'original:': 'à¦¶à§‡à¦– à¦®à§à¦œà¦¿à¦¬à§à¦° à¦°à¦¹à¦®à¦¾à¦¨'}\n","{'id': 'bengali--5802537117646660783-14', 'prediction': 'à¦®à§à¦°à§à¦¥à¦¿à¦°', 'original:': 'à¦®à§à¦°à§à¦¥à¦¿'}\n","{'id': 'bengali--3518785176444767715-2', 'prediction': 'à¦°à¦¯à¦¼à§‡à¦² à¦ªà§à¦°à§à¦¶à¦¿à¦¯à¦¼à¦¾', 'original:': 'à¦°à¦¯à¦¼à§‡à¦² à¦ªà§à¦°à§à¦¶à¦¿à¦¯à¦¼à¦¾à¦¤à§‡'}\n","{'id': 'bengali-6674191147754665656-2', 'prediction': 'à¦ªà¦¾à¦‡à¦“à¦¸à¦¾à¦¯à¦¼à¦¾à¦¨à§‡à¦œ', 'original:': 'à¦ªà§‡à¦¨à¦¿à¦¸à¦¿à¦²à¦¿à¦¨'}\n","{'id': 'bengali--8404986622637348674-3', 'prediction': 'à¦¶à§à¦°à§€à¦²à¦™à§à¦•à¦¾à¦°', 'original:': 'à¦­à¦¾à¦°à¦¤'}\n","{'id': 'bengali--7381837526075378596-1', 'prediction': 'à¦šà¦¤à§à¦°à§à¦¥ à¦¥à§‡à¦•à§‡ à¦¦à§à¦¬à¦¾à¦¦à¦¶ à¦¶à¦¤à¦¾à¦¬à§à¦¦à§€à¦°', 'original:': 'à¦šà¦¤à§à¦°à§à¦¥ à¦¥à§‡à¦•à§‡ à¦¦à§à¦¬à¦¾à¦¦à¦¶ à¦¶à¦¤à¦¾à¦¬à§à¦¦à§€'}\n","{'id': 'bengali-8775472783303060309-15', 'prediction': 'à¦…à¦°à§à¦œà§à¦¨', 'original:': 'à¦…à¦°à§à¦œà§à¦¨à§‡à¦°'}\n","{'id': 'bengali-5730130221372563642-10', 'prediction': 'à§¨à§® à¦œà§à¦²à¦¾à¦‡', 'original:': 'à§¨à§¦à§§à§¬ à¦¸à¦¾à¦²à§‡à¦° à§¨à§© à¦œà§à¦²à¦¾à¦‡'}\n","{'id': 'bengali--6695334746728483406-2', 'prediction': 'à¦à¦¾à¦à¦¸à¦¿à¦° à¦°à¦¾à¦¨à¦¿ à¦à¦¾à¦à¦¸à¦¿à¦° à¦°à¦¾à¦¨à¦¿à¦°', 'original:': 'à¦à¦¾à¦à¦¸à¦¿à¦° à¦°à¦¾à¦¨à¦¿'}\n","{'id': 'bengali--2660184311490318740-0', 'prediction': 'à¦…à¦­à¦¿à¦œà¦¿à§Ž à¦°à¦¾à¦¯à¦¼', 'original:': 'à¦®à§à¦•à§à¦¤à¦®à¦¨à¦¾'}\n","{'id': 'bengali-4524986788277724045-1', 'prediction': 'à¦¸à¦¾à¦«à¦¾ à¦ªà¦°à§à¦¬à¦¤à§‡à¦° à¦ªà¦¾à¦¦à¦¦à§‡à¦¶à§‡ à¦¯à¦¾à¦¯à¦¼à§‡à¦¦-à¦¬à¦¿à¦¨-à¦†à¦°à¦•à¦¾à¦®à§‡à¦° à¦¬à¦¾à¦¡à¦¼à¦¿', 'original:': 'à¦¸à¦¾à¦«à¦¾ à¦ªà¦°à§à¦¬à¦¤à§‡à¦° à¦ªà¦¾à¦¦à¦¦à§‡à¦¶à§‡ à¦¯à¦¾à¦¯à¦¼à§‡à¦¦-à¦¬à¦¿à¦¨-à¦†à¦°à¦•à¦¾à¦®à§‡à¦° à¦¬à¦¾à¦¡à¦¼à¦¿à¦¤à§‡'}\n","{'id': 'bengali--3707959970522014741-1', 'prediction': 'à¦®à¦¾à¦°à§à¦•à¦¿à¦¨ à¦¸à¦¶à¦¸à§à¦¤à§à¦° à¦¸à§ˆà¦¨à§à¦¯ à¦¬à¦¾à¦¹à¦¿à¦¨à§€', 'original:': 'à¦ªà¦¾à¦°à¦¿à¦¬à¦¾à¦°à¦¿à¦• à¦¬à¦¾à¦¡à¦¼à¦¿'}\n","{'id': 'bengali-7443250538964255015-1', 'prediction': 'à¦ªà¦¾à¦à¦š à¦¬à¦›à¦°', 'original:': 'à¦ªà¦¾à¦à¦š'}\n","{'id': 'bengali--7623066958616917497-1', 'prediction': 'à¦°à§à¦¦à§à¦°à¦¸à¦¾à¦—à¦° à¦¹à§à¦°à¦¦à§‡à¦°', 'original:': 'à¦°à§à¦¦à§à¦°à¦¸à¦¾à¦—à¦°'}\n","{'id': 'bengali-9107229136914417048-1', 'prediction': 'à¦¹à¦¾à¦™à§à¦—à§‡à¦°à¦¿à¦°', 'original:': 'à¦¹à¦¾à¦™à§à¦—à§‡à¦°à¦¿'}\n","{'id': 'bengali-4667499823130888007-3', 'prediction': 'à¦ªà¦¶à§à¦šà¦¿à¦®à¦¬à¦™à§à¦—à§‡à¦° à¦¬à§€à¦°à¦­à§‚à¦® à¦œà§‡à¦²à¦¾à¦° à¦•à§€à¦°à§à¦£à¦¾à¦¹à¦¾à¦° à¦¶à¦¹à¦°à§‡à¦° à¦¨à¦¿à¦•à¦Ÿà¦¸à§à¦¥ à¦®à¦¿à¦°à¦¾à¦Ÿà¦¿ à¦—à§à¦°à¦¾à¦®à§‡', 'original:': 'à¦¬à§€à¦°à¦­à§‚à¦®'}\n","{'id': 'bengali--5315201491935714820-0', 'prediction': 'à¦ªà¦¾à¦°à¦¸à§à¦¯à§‡à¦° à¦ªà§à¦°à¦¾à¦šà§€à¦¨ à¦œà¦¨à¦—à§‹à¦·à§à¦ à§€à¦°', 'original:': 'à¦ªà¦¾à¦°à¦¸à§à¦¯à§‡à¦° à¦ªà§à¦°à¦¾à¦šà§€à¦¨ à¦œà¦¨à¦—à§‹à¦·à§à¦ à§€à¦° à¦­à¦¾à¦·à¦¾'}\n","{'id': 'bengali--2223911595335362607-0', 'prediction': 'à¦ªà§à¦°à¦¾à¦—à§ˆà¦¤à¦¿à¦¹à¦¾à¦¸à¦¿à¦•', 'original:': 'à¦¨à¦¬à§à¦¯à¦ªà§à¦°à¦¸à§à¦¤à¦° à¦¯à§à¦—à§‡'}\n","{'id': 'bengali--8177010464512382506-0', 'prediction': 'à¦†à¦²-à¦•à¦¿à¦¨à§à¦¦à¦¿', 'original:': 'à§®à¦® à¦¥à§‡à¦•à§‡ à§§à§¨à¦¶ à¦¶à¦¤à¦¾à¦¬à§à¦¦à§€'}\n","{'id': 'bengali--261227273822015974-3', 'prediction': 'à¦¯à§à¦•à§à¦¤à¦°à¦¾à¦·à§à¦Ÿà§à¦°', 'original:': 'à¦¯à§à¦•à§à¦¤à¦°à¦¾à¦·à§à¦Ÿà§à¦°à§‡à¦° à¦¨à¦¿à¦‰ à¦®à§‡à¦•à§à¦¸à¦¿à¦•à§‹ à¦…à¦™à§à¦—à¦°à¦¾à¦œà§à¦¯à§‡à¦° à¦…à§à¦¯à¦¾à¦®à§‹à¦—à§‹à¦°à§à¦¦à§‹'}\n","{'id': 'bengali-8494320032744952978-0', 'prediction': 'à¦«à§‡à¦•à§ à¦“à¦¸à§à¦¤à¦¾à¦—à¦¾à¦° à¦²à§‡à¦¨', 'original:': 'à§§à§© à¦¨à¦®à§à¦¬à¦° à¦«à§‡à¦•à§ à¦“à¦¸à§à¦¤à¦¾à¦—à¦¾à¦° à¦²à§‡à¦¨'}\n","{'id': 'bengali-1441381660637739676-0', 'prediction': 'à¦¯à¦®à§à¦¨à¦¾ à¦¨à¦¦à§€', 'original:': 'à¦¯à¦®à§à¦¨à¦¾'}\n","{'id': 'bengali-7987011167425321150-3', 'prediction': 'à¦ªà§‚à¦°à§à¦£à¦¿à¦®à¦¾à¦°', 'original:': 'à¦ à¦œà§€à¦¬à¦¨ à¦¤à§‹à¦®à¦¾à¦° à¦†à¦®à¦¾à¦°'}\n","{'id': 'bengali-3279821707062003108-0', 'prediction': 'à§¨à§¦à§¦à§¨ à¦à¦° à§©à§§à¦¶à§‡ à¦®à¦¾à¦°à§à¦š', 'original:': 'à§¨à§¦à§¦à§¨'}\n","{'id': 'bengali--1070153120447023734-5', 'prediction': 'à¦œà¦¨', 'original:': 'à¦¨à¦¿à¦•à§‹à¦²à¦¾à¦¸'}\n","{'id': 'bengali-5988277494911723032-0', 'prediction': 'à¦¤à§Žà¦•à¦¾à¦²à§€à¦¨ à¦•à§à¦®à¦¿à¦²à§à¦²à¦¾ à¦œà§‡à¦²à¦¾à¦° à¦…à¦§à§€à¦¨à§‡ à¦¬à§à¦°à¦¾à¦¹à§à¦®à¦£à¦¬à¦¾à¦¡à¦¼à§€à¦¯à¦¼à¦¾ à¦®à¦¹à¦•à§à¦®à¦¾à¦° à¦—à§‹à¦•à¦°à§à¦£à¦˜à¦¾à¦Ÿ à¦—à§à¦°à¦¾à¦®', 'original:': 'à¦•à§à¦®à¦¿à¦²à§à¦²à¦¾ à¦œà§‡à¦²à¦¾à¦° à¦…à¦§à§€à¦¨à§‡ à¦¬à§à¦°à¦¾à¦¹à§à¦®à¦£à¦¬à¦¾à¦¡à¦¼à§€à¦¯à¦¼à¦¾ à¦®à¦¹à¦•à§à¦®à¦¾à¦° à¦—à§‹à¦•à¦°à§à¦£à¦˜à¦¾à¦Ÿ'}\n","{'id': 'bengali--204832994876246663-3', 'prediction': 'à¦—à§Œà¦°à¦®à§‹à¦¹à¦¨ à¦®à§à¦–à§‹à¦ªà¦¾à¦§à§à¦¯à¦¾à¦¯à¦¼ à¦¸à§à¦Ÿà§à¦°à¦¿à¦Ÿà§‡', 'original:': 'à¦‰à¦¤à§à¦¤à¦° à¦•à¦²à¦•à¦¾à¦¤à¦¾à¦°'}\n","{'id': 'bengali-4465126415643560051-0', 'prediction': 'à¦†à¦—à§à¦¨', 'original:': 'à¦¤à¦¾à¦®à¦¾à¦•'}\n","{'id': 'bengali--1538257118875639863-2', 'prediction': 'à§§à§®à§­à§¦', 'original:': 'à§§à§®à§­à§¦ à¦¸à¦¾à¦²à§‡ à§¨à§¨à¦¶à§‡ à¦à¦ªà§à¦°à¦¿à¦²'}\n","{'id': 'bengali--8867696482683155680-0', 'prediction': 'à¦¢à¦¾à¦•à¦¾ à¦¬à¦¿à¦­à¦¾à¦—à§‡à¦° à¦…à¦¨à§à¦¤à¦°à§à¦—à¦¤ à¦Ÿà¦¾à¦™à§à¦—à¦¾à¦‡à¦²à§‡à¦°', 'original:': 'à¦¢à¦¾à¦•à¦¾ à¦¬à¦¿à¦­à¦¾à¦—à§‡à¦° à¦…à¦¨à§à¦¤à¦°à§à¦—à¦¤ à¦Ÿà¦¾à¦™à§à¦—à¦¾à¦‡à¦²à§‡à¦° à¦¸à¦¨à§à¦¤à§‹à¦·à§‡'}\n"]}],"source":["picks = random.sample(range(0, len(wrong_prediction['bengali'])-1), min(40,len(wrong_prediction['bengali'])-1))\n","for i in picks:\n","    print(wrong_prediction['bengali'][i])"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:34.848465Z","iopub.status.busy":"2022-04-10T15:04:34.848221Z","iopub.status.idle":"2022-04-10T15:04:34.862329Z","shell.execute_reply":"2022-04-10T15:04:34.861655Z","shell.execute_reply.started":"2022-04-10T15:04:34.848431Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'id': 'telugu-227033373636002222-1', 'prediction': '168 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '168 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-675854620814783374-15', 'prediction': 'à°¸à±‡à°®à°¾ à°—à±à°°à±‚à°ªà±', 'original:': 'à°µà±‹à°¡à°¾ à°«à±‹à°¨à±'}\n","{'id': 'telugu--7150452250756477828-2', 'prediction': '490 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '490 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-8243050460142458655-0', 'prediction': '1961 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '1961 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-8129278576030709234-0', 'prediction': 'à°¤à±‚à°°à±à°ªà± à°—à±‹à°¦à°¾à°µà°°à°¿ à°œà°¿à°²à±à°²à°¾', 'original:': 'à°¤à±‚à°°à±à°ªà± à°—à±‹à°¦à°¾à°µà°°à°¿'}\n","{'id': 'telugu-2983175149020114154-5', 'prediction': 'à°…à°¨à± à°…à°°à±à°¬à±‹à°°à±, à°®à°¿à°šà°¿à°—à°¾à°¨à±', 'original:': 'à°…à°¨à± à°…à°°à±à°¬à±‹à°°à±, à°®à°¿à°šà°¿à°—à°¾à°¨à±\\u200c'}\n","{'id': 'telugu-9115912749184044385-1', 'prediction': 'à°¨à±†à°¦à°°à±à°²à°¾à°‚à°¡à±', 'original:': 'à°ªà°¶à±à°šà°¿à°® à°†à°«à±à°˜à°¨à°¿à°¸à±à°¥à°¾à°¨à±\\u200c'}\n","{'id': 'telugu--2073283125164763733-0', 'prediction': '39 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '39 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-8253928922712570370-4', 'prediction': '310 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '310 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-4831434226867109360-7', 'prediction': '1915 à°¨à°µà°‚à°¬à°°à± 30', 'original:': '53'}\n","{'id': 'telugu-5315675774639248518-0', 'prediction': 'à°ªà°¾à°•à°¿à°¸à±à°¤à°¾à°¨à±', 'original:': 'à°­à°¾à°°à°¤à°¦à±‡à°¶à°‚'}\n","{'id': 'telugu-8419414583131587883-0', 'prediction': '1011 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '1011 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--8810693408625259944-0', 'prediction': '153 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '153 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-512134417162412789-15', 'prediction': 'à°¬à±à°°à±‚à°¨à±ˆ à°‡à°‚à°Ÿà°°à±à°¨à±‡à°·à°¨à°²à± à°µà°¿à°®à°¾à°¨à°¾à°¶à±à°°à°¯à°®à±', 'original:': 'à°¬à±à°°à±à°¨à±ˆ à°¡à°¾à°²à°°à±à°²à±'}\n","{'id': 'telugu--3272466605711022131-2', 'prediction': '2,623', 'original:': '2704'}\n","{'id': 'telugu-2355058992665135572-0', 'prediction': '198 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '198 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-918133519643966911-0', 'prediction': 'à°ªà±‚à°£à±‡', 'original:': 'à°ªà±‚à°£à±‡, à°®à°¹à°¾à°°à°¾à°·à±à°Ÿà±à°°'}\n","{'id': 'telugu-4527046517267694248-0', 'prediction': '1179 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '1179 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-7280221406834583430-1', 'prediction': 'à°…à°²à°¿ à°—à°¡à±\\u200cà°²à±‹', 'original:': 'à°¢à°¿à°²à±à°²à°¿'}\n","{'id': 'telugu-3854057866257069688-1', 'prediction': 'à°ªà±à°¦à±à°µà°¸à°‚à°¤à°‚', 'original:': 'à°ªà±à°°à°¿à°¯à°¾à°¦ à°ªà±à°§à°¿à°°à±'}\n","{'id': 'telugu--9052359011095805857-3', 'prediction': '2324 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '2324 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--5004400969238813453-0', 'prediction': '190 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '190 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-1327025946082456622-4', 'prediction': 'à°‰à°²à±à°²à°®à± à°•à±†à°Ÿà±à°•à±à°®à°¾à°¯à±‡', 'original:': 'à°…à°°à°¿à°¨à±à°¥à°®à± à°…à°°à°¿à°¯à°®à°²à±à°®à±(2005)'}\n","{'id': 'telugu--534530456931366482-0', 'prediction': '2269 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '2269 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--397999538407153813-1', 'prediction': 'à°¸à°¾à°¹à±†à°¬à±\\u200cà°¬à±€, à°®à°¦à°¾à°°à±\\u200cà°¸à°¾à°¬à±', 'original:': 'à°®à°¦à°¾à°°à±\\u200cà°¸à°¾à°¬à±'}\n","{'id': 'telugu--530661135137008399-0', 'prediction': '816 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '816 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--1626927074160241543-0', 'prediction': '28 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '28 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--3316938560622730206-1', 'prediction': 'à°°à°¾à°œà°¯à±à°¯à°¶à°¾à°¸à±à°¤à±à°°à°¿ à°®à°°à°¿à°¯à± à°¸à±à°šà±‡à°¤', 'original:': 'à°°à°¾à°œà°¯à±à°¯à°¶à°¾à°¸à±à°¤à±à°°à°¿'}\n","{'id': 'telugu--6140267610656239828-1', 'prediction': '15 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '15 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--3406235526541671609-0', 'prediction': '671 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '671 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--4099819279895685485-0', 'prediction': '23 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '23 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-2788352386131681213-2', 'prediction': 'à°¡à°¾à°°à±à°²à±†à°¨à±† à°Ÿà±‹à°¨à°¾à°šà°¿à°¯à±‹ à°®à°°à°¿à°¯à± à°«à±à°°à°¾à°‚à°•à±à°²à°¿à°¨à± à°«à°¾à°•à±à°¸à±', 'original:': 'à°¡à°¾à°°à±à°²à±†à°¨à±† à°Ÿà±‹à°¨à°¾à°šà°¿à°¯à±‹'}\n","{'id': 'telugu--548921703247702173-0', 'prediction': '736 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '736 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--4139417899306970261-0', 'prediction': '0 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '0 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu-4617795002680831857-1', 'prediction': '14à°µ à°¶à°¤à°¾à°¬à±à°¦à°‚', 'original:': '14à°µ à°¶à°¤à°¾à°¬à±à°¦à°‚à°²à±‹'}\n","{'id': 'telugu--4733237526728225686-2', 'prediction': '1954 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²à°²à±‹', 'original:': '1954 à°¹à±†à°•à±à°Ÿà°¾à°°à±à°²'}\n","{'id': 'telugu--4536152537674333130-3', 'prediction': 'à°¬à±†à°Ÿà±à°Ÿà±€', 'original:': 'à°Žà°²à°¿à°œà°¬à±†à°¤à± \"à°¬à±†à°Ÿà±à°Ÿà±€\" à°…à°—à°¸à±à°¸à±€'}\n","{'id': 'telugu--4625427927478601702-1', 'prediction': 'à°•à±Šà°‚à°•à±à°¦à±à°°à±', 'original:': 'à°¤à±‚à°°à±à°ªà± à°—à±‹à°¦à°¾à°µà°°à°¿ à°œà°¿à°²à±à°²à°¾ à°°à°¾à°®à°šà°‚à°¦à±à°°à°ªà±à°°à°‚ à°¤à°¾à°²à±‚à°•à°¾ à°…à°¨à°ªà°°à±à°¤à°¿ à°¨à°¿à°¯à±‹à°œà°• à°µà°°à±à°—à°‚à°²à±‹à°¨à°¿ à°¬à°¿à°•à±à°•à°µà±‹à°²à± à°®à°‚à°¡à°‚à°²à±‹ à°‰à°¨à±à°¨  à°•à±Šà°‚à°•à±à°¦à±à°°à±'}\n","{'id': 'telugu-4078824087382361401-17', 'prediction': 'à°•à±Šà°‚à°•à°£à± à°¤à±€à°°à°­à±‚à°®à°¿', 'original:': 'à°¤à°®à±à°¹à°¿à°¨à°¿ à°˜à°¾à°Ÿà±, à°µà°°à°‚à°§ à°˜à°¾à°Ÿà±, à°¸à°µà°‚à°¤à±\\u200cà°µà°¾à°¡à°¿ à°˜à°¾à°Ÿà±'}\n","{'id': 'telugu-5457773759727946591-0', 'prediction': '2002 -2005 à°®à°§à±à°¯', 'original:': '2002'}\n"]}],"source":["picks = random.sample(range(0, len(wrong_prediction['telugu'])-1), min(40,len(wrong_prediction['telugu'])-1))\n","for i in picks:\n","    print(wrong_prediction['telugu'][i])"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-04-10T15:04:34.864193Z","iopub.status.busy":"2022-04-10T15:04:34.863822Z","iopub.status.idle":"2022-04-10T15:06:22.354622Z","shell.execute_reply":"2022-04-10T15:06:22.353742Z","shell.execute_reply.started":"2022-04-10T15:04:34.864033Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to bert-base-multilingual-cased-finetuned-model\n","Configuration saved in bert-base-multilingual-cased-finetuned-model/config.json\n","Model weights saved in bert-base-multilingual-cased-finetuned-model/pytorch_model.bin\n","tokenizer config file saved in bert-base-multilingual-cased-finetuned-model/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased-finetuned-model/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f82317213cb045b4920f9192cd7a20f2","version_major":2,"version_minor":0},"text/plain":["Upload file pytorch_model.bin:   0%|          | 32.0k/676M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e58847f59d34bb097ed0c1b9fb9fde7","version_major":2,"version_minor":0},"text/plain":["Upload file training_args.bin: 100%|##########| 3.05k/3.05k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7aad07d8d51c444a8773abc7e90f6901","version_major":2,"version_minor":0},"text/plain":["Upload file runs/Apr10_12-44-43_1ea24f5b9b85/1649594696.080163/events.out.tfevents.1649594696.1ea24f5b9b85.34.â€¦"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f34840574c648a683c1e29f3e6a8947","version_major":2,"version_minor":0},"text/plain":["Upload file runs/Apr10_12-44-43_1ea24f5b9b85/events.out.tfevents.1649594696.1ea24f5b9b85.34.0: 100%|##########â€¦"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["To https://huggingface.co/krinal214/bert-all-squad_ben_tel_context\n","   3e9b6a8..d88841d  main -> main\n","\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["To https://huggingface.co/krinal214/bert-all-squad_ben_tel_context\n","   d88841d..64cbb44  main -> main\n","\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"text/plain":["'https://huggingface.co/krinal214/bert-all-squad_ben_tel_context/commit/d88841dd62e28f8013a540a51142c596bcf6794b'"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["#trainer.push_to_hub()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
